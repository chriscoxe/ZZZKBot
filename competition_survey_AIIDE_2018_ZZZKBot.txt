AIIDE StarCraft AI Competition - Survey

Feel free to answer as many questions as you like, but it would be great if everyone answered everything!
Many people are interested in learning as much as possible about the bots that competed!
Please feel free to provide external references/links as necessary

Bot Name: ZZZKBot
Bot Race: Zerg
Author Name(s): Chris Coxe
Affiliation(s): Independent
Nationality(s): Australia and Britain
Occupation(s): Software Engineer/Developer

(These will be listed on the competition website)
Bot URL: https://chriscoxe.github.io/ZZZKBot/
Personal URL: https://www.linkedin.com/in/chriscoxe
Affiliation URL: N/A

Questions about your bot (please answer as many as you can, especially Q 1-3)

Q: What is the overall strategy/strategies of your bot? Why did you choose them?

Paraphrasing my old answer from https://github.com/chriscoxe/ZZZKBot/blob/master/competition_survey_AIIDE_2017_ZZZKBot.txt:

Same "Wu Wei" approach as previous versions, i.e. tailor some simple rushes (all 1-base build orders) and the number of defensive sunken colonies to some opponents based on their in-game player name. The rushes are: 4-pool, speedlings, hydras, mutas (and may decide whether to muta rush based on the enemy's race if they picked Random race), or neither. Then tech to either mutas or guardians, and all rushes eventually transition to trying guardians after enough rush units have died). After it has started teching it makes zerglings. After it eventually transitions out of guardians, it starts making other tech buildings and research/upgrades and some other unit types. However, the game has usually ended by that point, and it tends to spend all its resources on mutas and zerglings rather than other unit types like ultras, because of the kludgy way that unit types are prioritized. In addition, it also uses some special logic if the enemy is expected to forge fast expand ("FFE") or is expected to worker rush, although the logic for the latter does not work very well versus very many opponents.

The reason for the simplistic overall strategy/approach is because it was only intended to be a throw-away proof of concept bot, but because it was good at winning games against other bots (and for fun). I.E. extracts: "A simple throw-away proof-of-concept cheesy kamikaze 4-pool bot implemented in a short amount of time to reach low-hanging fruit.", "Has some simple logic for scouting, targeting and resource-gathering. Apart from targeting its micro is very limited. Stays at 9 or 10 supply for several minutes of in-game time then techs straight to mutalisks or guardians (on only 1 base... soon runs out of gas...) in an attempt to finish off static defences of idle opponents, and mutalisks in an attempt to destroy lifted buildings.", "Originally implemented in a quick and dirty fashion so releases would be ready for the CIG & AIIDE 2015 Starcraft AI competitions.".

There didn't seem to be much gain in adding much logic for transitioning out of the 4-pool strategy to other units because if 4-pool fails you are probably going to lose very quickly if the opponent is any good. I decided to continue kamikaze'ing zerglings to keep up the pressure in case it slowly wears down the opponent or in case the opponent makes a bad decision to transition out of their strategy. I did, however, add logic to make it transition after a frame number threshold to mutalisks then guardians in case all that is left of the enemy is static defence or lifted buildings. There is only so much you can do to improve the 4-pool strategy though, so I added a speedling build order which I hoped might be more effective against some opponents. In this strategy, it only starts sending zerglings out when the metabolic boost research finishes, then not long afterwards it transitions to mutalisks, then transitions to guardians if any mutalisks die. I also added a muta rush and a hydra rush. As I said, apart from targeting its micro is very limited - I still haven't worked on it. Combat units simply keep attacking something. I didn't get around to adding any logic to make them kite or retreat or regroup or avoid dangerous threats to themself like static defences.

Q: Did you incorporate any of the following AI techniques in your bot?
   If you did, please be as specific as possible

   a) Search-Based AI (Path-Finding, A*, MiniMax, MCTS, etc)

	 Yes: idle workers (and workers that have just returned minerals/gas to the base and are now/still a mineral gatherer) are allocated to unallocated mineral patches near the starting base using a greedy search algorithm which is based on the best worker's total distance between the base and an unallocated mineral patch (most important) plus distance from the worker to that mineral patch (less important). When there are no more unallocated mineral patches available, any remaining idle workers are all simply allocated to the mineral patch that is closest to the base (which will probably make workers bounce around between mineral patches somewhat, although they may settle after a few trips).

   b) Offline Machine Learning (Supervised or Unsupervised, but not RL)

	 Yes: the hard-coded set of initial creep locations for Zerg bots on AIIDE maps were incorporated into the ZZZKBot source code after an earlier version of ZZZKBot dumped the tile positions of creep around a zerg base at the start of the game while playing a few games on each of those maps. This information is used when scouting to narrow down the possible starting locations of a zerg opponent. You don't necessarily need to see one of their buildings - you just need to see the creep near it (or the absence of creep where you would expect creep to be if they had started there).

   c) Offline Reinforcement Learning

	 Yes: I decided which initial strategy parameter values to use vs particular player names based on what an earlier version of ZZZKBot learned had the best win rate playing against them (well, the recent versions of other bots that I could get a copy of at the time, anyway).

   d) Online Learning of any kind (Including competition file IO for strategy selection)

	 Yes: competition file IO for strategy selection. Details (pasted from AIIDE 2017 survey answers):

	 ZZZKBot records game info to persistent file I/O via opponent-specific append-only binary (DAT) files in the read/write folders. At the start of each game, ZZZKBot uses the number of wins and number of losses from the corresponding DAT file for that opponent in some simple hard-coded logic to learn/experiment which strategy parameter values to use for the current game. The scenario criteria that are considered which vary in this competition (apart from the opponent and whether they are Protoss/Terran/Zerg/Random race) from least specific to most specific are: the number of start positions in the map, the map hash, my start location. The strategy parameters that are decided are the type of rush to use, the special flags for whether the enemy is expected to forge fast expand or worker rush, and the number of defensive sunken colonies to build (which may vary according to race if the enemy is Random race). If it won the last game in the most specific scenario that matches the current scenario, it will always use the same strategy parameter values. Alternatively (i.e. if it is known to have lost the last game in the most specific scenario that matches the current scenario), if its win rate is >= 80% or it has lost 4 or less games total (i.e. in all scenarios vs that opponent & race) it will use the same strategy parameter values as the lost game, otherwise it will either pick a different combination of strategy parameter values that has won at least once in a less specific scenario that matches the current scenario (if the expected win rate is good enough of a randomly selected (but weighted by win rate) combination of strategy parameter values, excluding the strategy parameter values combo that we just lost for) otherwise it will pick a combination of strategy parameter values at random according to some probability weightings I have pre-defined. Unfortunately there are bugs in this logic (in the AIIDE 2017 version) that cause learning to be unnecessarily slow vs Random race bots, and sometimes (but thankfully quite rarely) causes it to pick a combination of parameter values that were not designed to be used together which cause the bot to get stuck waiting and never building a sunken colony before doing anything such as building more drones/buildings/combat units or attacking, so it becomes extremely passive and probably loses the game.

   e) Influence Maps

	 No.

   f) Custom Map Analysis

	 No online map analysis, but the set of initial creep locations for Zerg bots on AIIDE maps was incorporated into ZZZKBot as described in part b.

   g) Hard-coded or rule-based strategy / tactics

	 Yes. ZZZKBot is primarily a rule-based bot.

   h) Analysis of bots from previous competitions / hard-coded specific bot counter strategies

	 Yes: see part c.

   i) Any techniques not mentioned here

	 Pasting from AIIDE 2017 survey answers:

	 Most of the decisions in the bot are achieved by simple hard-coded prioritization of the various considerations involved. E.g. the decision for which enemy unit to target is simply distance-based spiral searches with a hard-coded maximum distance threshold specified (via calls to BWAPI's getBestUnit() and getClosestUnit() functions) using simple heuristics mainly based on an ordering of attributes, with units that are in mutual weapon range first, threatening enemy units next, and an ordering of the various enemy unit attributes such as isPowered(), unitType() (the ordering of the various unit types is hard-coded), an estimate of enemy unit life force (a kludge based on HP, shields, armor, defense matrix points if it is defense matrixed), then a bunch of other ordered enemy unit attributes such as whether it is constructing a building. Another example is the decision for which unit to build/train next - a simple ordering is used (i.e. a kludge mainly just the order the various unit command calls appear in the source code) with some heuristics based on what type of rush we are doing, what tech buildings we need, how many drones we have, how many drones have died, how many of the rush unit type have died. Tech transitions are mainly triggered based on how many of our units of a particular unit type have died, or in some cases a hard-coded frame count threshold.

	 Uses randomization, i.e. selects the combination of strategy parameters values randomly in some cases, and also randomizes each scouting unit's target position after all possible enemy start locations have been scouted and there are no known (landed) enemy buildings (and being more likely to select a target position that is not currently visible than a position that is already visible).

Q: How did you become interested in Starcraft AI?

Pasting from AIIDE 2017 survey answers:

I have always loved the game of Starcraft. I have been interested in Starcraft AIs ever since I first heard they existed via posts on the slashdot forum. The main post I recall was a link to an article about how the Berkeley Overmind bot won the 2010 Starcraft AI competition - at the time of writing (29th September 2017) you can see it as a series of articles now at: https://arstechnica.com/gaming/2011/01/skynet-meets-the-swarm-how-the-berkeley-overmind-won-the-2010-starcraft-ai-competition/

Writing a Starcraft bot is a good fit for my interests in problem solving, programming, software engineering, game theory, AI/ML, strategy games (Starcraft in particular), and competition. It's a lot of fun, and often farcical.

Q: How long have you been working on your bot?

Pasting from AIIDE 2017 survey answers:

I started writing ZZZBot in mid July 2015 for CIG 2015. ZZZBot (which became ZZZKBot) was my first competitive bot, but before that I had tinkered with BWAPI (see below), which helped me to learn BWAPI and the game mechanics. I usually only work on my bot just before a competition deadline...

Q: About how many lines of code is your bot?

Pasting from AIIDE 2017 survey answers:

The AIIDE 2017 version is 5382 lines total (for everything including comments and blank lines etc), i.e. 5278 lines in C++ files and 104 lines in the vcxproj file. There is also some basic documentation in TXT files. There's quite a lot of source code duplication because I wrote it in a hurry and was planning to throw away the source code when I wrote it (ZZZBot for CIG 2015 was only intended to be a simple throw-away proof of concept bot!), and I haven't got around to tidying it up much. If you want to examine/use the source code, be warned that the source code is messy, full of kludges, undocumented, has undocumented limitations/gotchas, and lacks hardly any good architecture/abstraction/encapsulation (e.g. the logic is almost all in one method (onFrame()) and uses static variables, and significant duplication of source code).

Q: Why did you choose the race of your bot?

Pasting from AIIDE 2017 survey answers:

When I started writing the bot I wrote a simple strategy that used very early aggression as all three races. I was surprised how effective the initial zerglings were, even against some existing strong bots. Since then, I've decided to stick with Zerg rather than switching to Protoss or Terran or Random. I'd like to write a Random race bot, but it would require much more development time and computational resources to properly test it. I thought my time would be better spent improving the Zerg logic.

Q: Did you use any existing code as the basis for your bot? If so, why, and what did you change?

Pasting from AIIDE 2017 survey answers:

So that I could get started quickly, as a basis I just started with the BWAPI version 4.1.2's ExampleAIModule project and modified it, then subsequently upgraded to use a later version of BWAPI. I still haven't got around to using a library such as BWTA2/BWEM for terrain info.

Q: What do you feel are the strongest and weakest parts of your bot's overall performance?

Pasting from AIIDE 2017 survey answers:

Strengths: It's a cheesy N-trick pony. All it can do is some simple 1-base rush builds, with little or no follow-up. Its only strength lies in the fact that many existing bots are vulnerable to cheesy builds like this. It may be able to learn which type of rush is most effective.

Weaknesses: apart from targeting, combat micro is almost non-existent - the only logic for combat micro is whether to wait at my base after morphing (only used in some types of rush while waiting for some tech to finish), or attack (almost all other scenarios), or defend my base (very rare). Also, it never expands. It would be useless against humans - it was not intended to be tested against humans - but it is effective against various other bots.

Q: If you competed in previous tournaments, what did you change for this year's entry?

No new entry (the AIIDE 2017 version is re-used).

Q: Have you tested your bot against humans? If so, how did it go?

I haven't tested it personally, but Sejong University tested some bots including mine against http://wiki.teamliquid.net/starcraft/Stork and some amateurs in showmatches in October 2017.  Mine lost 0:1 vs Stork, and won 1:0 vs the two amateurs. Links:
https://www.technologyreview.com/s/609242/humans-are-still-better-than-ai-at-starcraftfor-now/
https://cilab.sejong.ac.kr/home/doku.php?id=public:starcraft_human_vs_ai

Q: Any fun or interesting stories about the development / testing of your bot?

Pasting from AIIDE 2017 survey answers:

Before I started writing a competitive bot, while I was tinkering with BWAPI for the first time, I wrote a bot just for experimentation purposes. It identifies all allowed unit commands for all my units every 3 in-game seconds and issues one out of all of those commands at random. For commands that take arguments, it picked argument value(s) from among the allowed argument values at random, e.g. it only issues a build command for buildable locations. It was able to issue every possible command in the game that was allowed at that moment, including all spells and abilities. It was useless competitively of course but it was interesting to watch it on full speed playing against itself, especially if I helped it by making a few extra workers for it at the start. It would slowly build its base up (including gathering minerals, making a refinery and gathering gas), train units, research/upgrade, and have strange skirmishes with enemy units.  When playing by itself, at some point it would inevitably wipe itself out by attacking its own buildings with workers or zerglings or marines or air units or whatever. On test maps where you start with lots of late-game units it was interesting to watch it cast all kinds of spells and abilities etc on its own units and enemy units, load and unload units, lift and move and land Terran buildings, nuke/storm itself, make hallucinations, mind control critters etc.

Q: Any other projects you're working on that you'd like to advertise?

Pasting from AIIDE 2017 survey answers (still pertinent):

Support/donations/sponsorship or perhaps even job offers (would be my dream job!) to write or help write a "proper" Broodwar or SC2 bot that actually uses some sophisticated AI/ML techniques (perhaps alongside minimal hard-coded logic?), possibly eventually using more appropriate hardware would be helpful, i.e. via https://www.paypal.me/quatari or alternatively add me in LinkedIn but be sure to mention it's about Starcraft AI otherwise I may ignore connection requests (https://au.linkedin.com/in/chriscoxe) or contact me at chris (dot) coxe (at) gmail (dot) com.

So far, I've been working on my Starcraft bot sporadically just before competition deadlines just as a hobby, using simple techniques to reach low-hanging fruit against other bots, using my existing personal hardware, but I have been following the Broodwar and SC2 AI scene and papers closely and have a lot of ideas for more sophisticated (and resource-intensive...) AI/ML techniques I would like to experiment with in a bot and would love to work on something more serious/useful/ambitious in Broodwar/SC2 AI.

Optional Opinion Questions:

Q: What is your opinion on the current state of StarCraft AI? How long do you think before computers can beat humans in a best-of-7 match?

Currently (17th November 2018), I still have no idea whether or when they will start winning against the best humans. Unfortunately, even if BWAPI-based bots do start winning against the best humans, I think it would be controversial because I expect that humans would argue that BWAPI-based bots have an unfair advantage due to having a lot more information than what the humans have access to, and less restrictions on what actions can be performed. Humans only have access to the pixels (including just the enemy unit animations & audio cues for their orders) for the current camera view (not the rest of the map that is within their units' vision), the current state of the HUD, and audio cues (from units on-camera, and e.g. siege tanks sieging off-camera nearby). BWAPI bots have immediate access (don't need to spend frames to selecting each unit before information about each unit appears in the HUD) to all game state of everything that is within their units' vision (even if it is outside of the current camera view) and although many enemy unit attributes are hidden from bots (e.g. whether an enemy unit is a hallucination), bots do have access to some internal game state that humans do not. For example, access to the information about enemy units' orders even before their action animations start, e.g. the destination and type of building that an enemy SCV is on its way to construct; knowing the target location of an order/spell/ability before the animation even appears (e.g. storm dodging); knowing which unit an enemy unit is targeting, e.g. the target of a scarab from an enemy reaver. Also, bots are not limited to information and issuing orders in terms of individual pixels, so can see all units even though they may be hidden in a stack (e.g. can see units under a floating Terran building, and can target them), and can easily distinguish between stacked units (e.g. focus fire the enemy mutalisk that has the lowest hit points even if it is stacked with many other enemy mutalisks and is not the top-most mutalisk; can immediately pull an irradiated mutalisk out of their stack of mutalisks even though it is not the top-most mutalisk). If bots could be restricted to using a pixel-based (like the SC2 API's rendered interface) & audio-based interface for gathering information and performing actions in an identical way to a human, other potential arguments about fairness playing against humans would be easier to address. E.g. the ability of bots to have a very high number of actions per minute (APM) might be considered to be too much of an advantage over humans (especially if they exploit it to beat humans, rather than winning by good strategic decision-making), so to level the playing field, bots could be weakened when playing against humans by enforcing additional rules about throttling the maximum peak burst and/or average APM into the interface (e.g. a limit for max actions per frame, and a limit for max actions for every 24 frame sliding window, and similarly for 48 frames, 120 frames, 240 frames, 1440 frames, or whatever). However, I imagine it would be difficult and time-consuming to implement a pixel based interface in BWAPI (and perhaps some kind of signals for audio cues somehow) for bots to use when playing against humans.

The rest of my answer is pasted from my AIIDE 2017 survey answers, and I think it's still pertinent:

A lot of traditional game AIs (for simple games anyway) and machine learning problem AIs can be tested within a split second to get a decent estimate of how strong they are. Unfortunately, currently, a single bot-vs-bot game of Starcraft against most BWAPI-based bots (i.e. almost all existing AIIDE/CIG/SSCAIT bots) can typically take roughly 30 real-world seconds at full speed. To get a decent idea of how strong a bot is, you need to test it against many BWAPI-based bots, preferably on a variety of maps. Also, enemy bots can learn between games, so a strategy that was very successful in the first few games may not be very successful at all after the enemy bot has played enough games. Against opponent bots that learn slowly, it could take dozens or even hundreds of games before it starts to become clear that a strategy that was effective initially isn't going to be effective in the long-term. If both bots are able to learn between games then the results may be very chaotic initially and may take many games for the win percentage to stabilize (or it may never stabilize in the worst case depending on how they are written, although this is very unlikely) because they may each react to each other's adjustments between games. Within the last year, tscmoo has written an implementation of the Broodwar game engine in the OpenBW project (see http://www.openbw.com/ and https://github.com/openbw). This will make it a lot easier to code and run simulations of approximations of forward models without needing to run the Starcraft process, although some important game state must still be hidden from each player and it would be cheating to accurately predict Broodwar's randomization logic that it uses for RNG in some parts of its game engine. Currently, as far as I know, there is currently no quicker way to test a bot against most existing AIIDE/CIG/SSCAIT bots than to actually run the other bots by injecting them via BWAPI into a Starcraft process in Windows or WINE etc using tools like StarcraftAITournamentManager. Consequently, learning techniques that require testing vs most other AIIDE/CIG/SSCAIT bots can only learn at that pace, and similarly for the development cycle in general.

Humans are very good at identifying new kinds of weakness that have not been identified before and quickly and effectively exploiting them, whereas AIs are currently very bad at this. In Starcraft for the bots available currently, as a human it is often easy to exploit bugs in the bot that the bot has no code for learning to respond to it (e.g. gas steal against a bot that has no logic to properly predict/prevent/respond to gas steal and plays poorly or distractedly if its gas is stolen) or a simple tactic (e.g. lure) or a simple technique (e.g. walling) or a simple hard-counter strategy (e.g. a particular opening build order) to consistently beat a particular bot. Once the word gets out about a bot's weaknesses, it isn't long before humans are able to consistently/always beat it, even quite weak human players. Of course, the bot's author might later be able to make a change to remove the weakness, then humans will look for other/new weaknesses...

At present, it wouldn't surprise me if a bot might occasionally beat a strong knowledgeable Starcraft player within a few years from now if they aren't used to playing against bots, or didn't know anything about the bot beforehand and the bot is adept at some cheesy strategies that took them by surprise with a little luck as a once-off. This might tend to happen if the bot plays as Random race on large maps and the human was often unlucky when scouting. I'm sure if the human prepares by playing against the same version of the bot beforehand they will soon notice a weakness and be able to exploit it and learn how to beat the bot before they actually play in the tournament.

That said, if it does happen soon that the same version of a bot beats several strong knowledgeable human players consistently and continuously even if the humans prepare by playing against it, which I doubt, I would guess that the bot would be exploiting a human's limited multi-tasking ability and limited actions-per-minute ("APM"). It might make use of the bot's high APM, especially in cheap tactical tricks that are difficult or time consuming for a human to do but effective for a bot to do (e.g. splitting units against splash damage, unloading and loading units vs units that fire projectiles so they miss, micro when kiting using multiple units that is nearly frame-perfect). It might rely on the ability of a bot to do multi-pronged attacks and constantly harass multiple bases at once, with fast units that kite and are positioned and maneuvered well to avoid taking damage. This might force the human to focus on defending and micro, leaving the human with little time to spend on attacking/macroing/scouting/expanding/improving their economy. This might enable the bot to gain map control and expand all over the map, then dominate or starve the human. As prior research has shown, a bot is also able to get a slight economic advantage by improving the control of gatherers to reassign gatherers to mineral patches that have better round trip times. This might eventually tip the balance in the bot's favor in some games, due to the snowball effect.

Q: What do you feel is the biggest hurdle (technological or otherwise) in improving your bot's AI?

Pasting from my AIIDE 2017 survey answers (I think it's still pertinent, although I gather that OpenBW-based bots that don't run a process for Starcraft can run significantly faster than BWAPI-based bots):

When I first started tinkering with BWAPI, the main hurdle was learning what Starcraft does under the covers (e.g. what the effects are exactly when you issue the various kinds of unit commands, and pathfinding), learning what BWAPI can and can't do and how to use it, e.g. Starcraft game mechanics like how the latency frames system works, understanding the attack animation frame system, game/unit state attribute accessibility, and pitfalls such as needing to prevent spamming attack commands. Since then there have been some great tutorials/blogs made available that would have helped me then, and it is easier to write bots now.

Now, the main concern for me is being able to increase the number of games played per hour when testing with the hardware I have available so that after I make a change to my bot, I can more quickly get feedback for how the change affected its strength (and any significant effects e.g. matchups or maps it is now much stronger or much weaker for) by testing the bot against more other bots and/or on a wide range of maps and/or playing more games (and playing many more games against bots that use inter-game learning than against bots that don't). The game rate is already fast for a small network of VMs using StarcraftAITournamentManager and I doubt it can be sped up much further or made much more efficient for the hardware I have available (because Broodwar's game engine logic still needs to run for every frame). Adding more computing power by adding more machines/VMs would help a lot because the testing can be quite scalably parallelized (at least until inter-game learning effects start to become a limiting factor anyway).

Q: Which bots are the most interesting to you and why?

Pasting from AIIDE 2017 survey answers:

Any bots that use learning techniques and try to minimize hand-crafting as a design approach, because it is more interesting and inspiring to see bots learning for themselves, and they may come up with novel ways of solving problems and playing Starcraft that nobody has thought of yet (e.g. I gather that the 7 roach rush build order in Starcraft 2 was found using a genetic algorithm, although of course I can't guarantee that a human didn't think of it first).

AIIDE Specific Question:

Q: Do you feel that the current format of iterated round-robin win percentage
   is a good indicator of bot skill ranking? If not, how would you change it?

	 If you stick with a competition that only allows one version of each bot (authors can't update their bot at all during the competition) - yes, I think it is fine. If you turn it into a ladder that runs continually all year round, where bots can be updated at any time, and award prizes at the annual AIIDE conference, this would encourage an arms race between bots. Excessively exploitative or surprise strategies would no longer be so strong, because other authors would have the opportunity to adjust their bot's play. They would have an incentive to add their bot to the ladder as early in the year as possible and upload improvements often, rather than potentially keeping their entry secret for up to a whole year until the annual deadline for the competition. You could schedule bot-vs-bot matchups and map selection randomly (no voting) and award prizes based on, say, each bot's time-weighted ELO over its best 3 month period in the last year. It might be time-consuming to manage if you still require organizers to compile every new version themselves from source though.
